{{Title|title=Computer Security Mental Model}}
{{Header}}
{{#seo:
|description=Critically Important Mental Models for Computer Security, Threat Modeling
|image=https://www.whonix.org/w/images/d/d2/Mentalcomputer4801544640.png
}}
[[image:Mentalcomputer4801544640.png|thumb]]

= Threat Modeling = 

== Definition ==

Various wiki chapters reference the concept of threat modelling. Statements like "Conduct a personal threat assessment before proceeding" often appear before instructions that install additional software or change specific system configurations. Despite this warning, many users are unfamiliar with the concept or unsure how to conduct a proper assessment in their circumstances. In simple terms, threat modeling refers to: <ref name=threat_modelling1>https://www.privacyguides.org/threat-modeling/</ref> <ref>https://csrc.nist.gov/CSRC/media/Publications/sp/800-154/draft/documents/sp800_154_draft.pdf</ref>
<blockquote>A threat model is a list of the most probable threats to your security/privacy endeavors. Since itâ€™s impossible to protect yourself against every attack(er), you should focus on the most probable threats. In computer security, a threat is a potential event that could undermine your efforts to stay private and secure.

By focusing on the threats that matter to you, this narrows down your thinking about the protection you need, so you can choose the tools that are right for the job.</blockquote>

<blockquote>Threat modeling is a form of risk assessment that models aspects of the attack and defense sides of a particular logical entity, such as a piece of data, an application, a host, a system, or an environment. The fundamental principle underlying threat modeling is that there are always limited resources for security and it is necessary to determine how to use those limited resources effectively.</blockquote>

== Threat Model Examples ==

Devising a threat model requires a ''realistic'' assessment of probable threats (adversaries) and the available mitigations that are feasible to apply. Adversaries will have varying motivations, skill and resources at their disposal. The Electronic Frontier Foundation (EFF) has noted proper security planning necessitates answering five key questions to determine what should be protected, from whom, and the potential consequences of a breach: <ref>https://ssd.eff.org/en/playlist/academic-researcher</ref>

# What do I want to protect?
# Who do I want to protect it from?
# How bad are the consequences if I fail?
# How likely is it that I will need to protect it?
# How much trouble am I willing to go through to try to prevent potential consequences?

To better understand these concepts, consider these questions in further detail below.

'''Table:''' ''Threat Modeling Concepts'' <ref name=threat_modelling1 />

{| class="wikitable"
|-
! scope="col"| '''Concept'''
! scope="col"| '''Description'''
|-

! scope="row"| What I want to protect
| In terms of computing and digital security, this refers to protecting "assets" which is a type of information like browsing history, files, messages, emails, personal contacts and so on. To determine your assets, take note of what data is stored and where, who potentially has access to it, and what protections are in place to prevent unwanted access.
|-

! scope="row"| Who I am protecting it from
| Consider who might target you or your information; this is your "adversary". Potential adversaries include: family, friends or ex-partners; employers; business competition; researchers; government entities; malicious hackers; advertisers; corporations; and the IC.
|-

! scope="row"| How likely protection is required
| A proper risk assessment is required. To determine the probability of threats being actualized, consider the capabilities of adversaries and their motivation, for example: <ref>This is admittedly a subjective process which is different for every individual. Even though some risks are low, they may be unacceptable to specific people. On the other hand, some people disregard probable threats, because the consequences are assessed as inconsequential.</ref>
* Family, friends and ex-partners are likely to be unskilled and unmotivated threats.
* Advertisers and employers are generally unskilled and motivated threats.
* Some corporations are skilled, but unmotivated threats (such as a mobile device provider).
* Security researchers, other corporations (like Google and Facebook), competent hackers and law enforcement are skilled and motivated threats. They also have access to limited global resources.
* The IC are highly skilled, highly motivated and have significant global resources.
|-

! scope="row"| Impact of an adversary breach
| Skilled adversaries have multiple opportunities to access, exfiltrate, delete or corrupt data, but the motives and tactics will differ depending on the specific adversary. For example, advertisers will remain focused on highly detailed profiling, government may focus on reading private communications of journalists, the IC may seek to establish full monitoring of systems associated with political activists and so on. Consider how harmful a successful breach by an adversary would be -- what they can do with private data -- and the probability of this occurring; the likelihood obviously increases with more skilled adversaries. <ref>For example, mobile phone providers can access all phone records, unencrypted communications are vulnerable to hackers on Wi-Fi networks, and government agencies can likely backdoor any Internet-connected device.</ref>
|-

! scope="row"| Effort exerted on improved security
| Security is a process and not an end product. Every individual has different priorities, threats, resources, and capabilities. This means the "right" strategy is a balance of personal time, convenience, privacy and cost. Threat models and mitigation strategies will be very different for:
* A journalist willing to disclose whistleblower secrets, since this requires protection from government entities.
* A member of the public who is simply seeking to thwart profiling by online advertisers/global technology companies. 
* Managers protecting themselves against potential hackers employed by competitors for the purpose of corporate espionage.
|-

|}

== Threat Model Guides ==

To better protect yourself against surveillance by adversaries, it is recommended to consult the following EFF "Security Scenarios". Detailed advice is provided for various user groups regarding appropriate resources, tools and tips to mitigate potential threats: <ref>https://ssd.eff.org/en/module-categories/security-scenarios</ref>
<div style="column-count:2;-moz-column-count:2;-webkit-column-count:2">
* [https://ssd.eff.org/en/playlist/lgbtq-youth LGBTQ Youth]
* [https://ssd.eff.org/en/playlist/academic-researcher Academic researcher]
* [https://ssd.eff.org/en/playlist/human-rights-defender Human rights defender]
* [https://ssd.eff.org/en/playlist/mac-user Mac user]
* [https://ssd.eff.org/en/playlist/journalism-student Journalism student]
* [https://ssd.eff.org/en/playlist/activist-or-protester Activist or protestor]
* [https://ssd.eff.org/en/playlist/journalist-move Journalist on the move]
* [https://ssd.eff.org/en/playlist/online-security-veteran Online security veteran]
* [https://ssd.eff.org/en/playlist/want-security-starter-pack Want a security starter pack?]
</div>

To learn more about the {{project_name}} threat model, see [[Dev/Threat_Model|here]].

= Mental Model Overview =

== Introduction ==

For effective computer security it is crucial to construct a rough mental model of how the computer broadly functions on a technical level. The majority of program code that is run on a computer is from diverse sources. Some software is sourced from "trusted" <ref name=trusted>"Trusted" here refers to enforced trust, not because it is an individual decision to trust.</ref> vendors (of out necessity), while others stem from less-trusted or untrusted sources. The spectrum of trust arises because it is required for useful functionality in general computing. <ref>In contrast, in the example of a classic washing machine -- without an Internet conenction, sophisticated software or remote controls -- the only trusted program code by the washing machine vendor is that which is used to draw information on the display.</ref>

When a computer boots, there are four basic steps:
# When a computer is fully powered off and it previously did not have a battery or power cord connected, when it is powered on the first thing that occurs is the hardware initialization (which is invisible to the user).
# During the boot process, the first visible sign to the user is the BIOS. It is an essential skill for a user to visually recognize the BIOS.
# The next visible sign is the bootloader, such as grub on Linux.
# Disregarding intermediary steps, <ref>Such as kernel initialization, initramfs or dracut, systemd, and single user mode in Linux.</ref> the next visible sign most users will see is the operating system desktop environment.

By booting any computer with an operating system and associated software:
# The hardware, BIOS is ultimately trusted. <ref name=trusted />
# The operating system is highly trusted. <ref name=trusted /> <ref>
Unless there is hardware, firmware or BIOS level malware it is always possible to replace a compromised operating system with a clean operating system.
</ref>
# Less trusted are applications like web browsers, for example Firefox, Chrome or Tor Browser.
# Least trusted are the contents shows by applications such as a website in a web browser.

Based on the simplified model above, it is therefore important to know which program code (application or program) usually <ref>Aside from malware-compromised code.</ref> has associated permissions to draw windows in certain places.

== Threat Assessment ==

When an appropriate mental model has been adopted, it becomes easier for users to detect legitimate threats or those which are most likely false alarms. As an example, consider the following image which is genuine.

'''Figure:''' ''Tor Browser DuckDuckGo Website in VirtualBox VM Utilizing {{project_name}} Xfce''

[[File:Tor_browser_duckduckgo2.png|1200px]]

In contrast, the following image is an example of a scam which "alerts" the user with a false alarm. 

'''Figure:''' ''Internet Explorer <code>systembrowsing.com</code> Scam Popup in Windows'' <ref>https://malwaretips.com/blogs/systembrowsing-com-removal/</ref>

[[File:Systembrowsing-com-popup.jpg]]

More experienced users with the proper mental model will quickly ascertain the <code>systembrowsing.com</code> alert as a scam. The reason is <code>systembrowsing.com</code> is just a website inside the browser window, without broader access to the user's operating system (in order to possibly detect local viruses).

It is important to mentally compartmentalize the different parts of a computer system:

* operating system: <code>Windows</code>
* application: <code>Internet Explorer</code>
* website: <code>systembrowsing.com</code> (scam)

By adopting a skeptical mindset and the mental model above, experienced users quickly realize the image's warning cannot be trusted, solely because it states a virus has been detected; it is just text on a website. This means the website is also the source of the message, while the browser is just the messenger. Finally, the operating system and computer display the final message destination, but the message is not actually generated by a virus scanner.

Website messages stating your computer is infected with viruses or other malware are almost always false. This does not mean your computer is not actually infected, it could be for completely unrelated reasons. But even in this case the website would be unaware of it -- websites only have permission to show text, images or audio in the web browser. <ref>Ignoring deprecated, dangerous technologies such as Internet Explorer with ActiveX.</ref> Simply put, web browsers are neither designed, nor supposed to scan for viruses; if that was the case, it would be well documented.

Similar to bulk phishing attempts, scam websites that resort to these tactics do not usually possess the skill to exploit vulnerabilities in web browsers or operating systems. If they did, they would just compromise the victim's computer instead of relying on a ruse. <ref>In other words, the attacker would not need to instruct users to compromise themselves.</ref> A highly skeptical user will disregard such messages, or possibly seek advice or conduct appropriate research before taking any action, thereby staying safe from such attacks. Always remember that various [[Social_Engineering#Psychological_Techniques|psychological techniques]] are relied upon by attackers (including urgent instructions), leading to security compromises. 

The take-home messages is while users must trust their operating system and less so their applications, utmost skepticism should be the default position concerning claims made by websites. Users who are unaware of this concept remain a highly vulnerable target.

== Best Practices ==

When seeing any information, text, audio or image shown by the computer, the user should ask oneself the following questions:

* Which program code is likely generating this message?
* Which program code is likely drawing this (part of this) window?
* Does this application have access to this information?
* How does this application have access to this information? <ref>
For example nowadays browsers can ask for permission to use the Microphone or IP addresses can be used to determine the location of a user.
</ref>

This model is not only useful to avoid scams but also to diagnose, fix issues.

Learning about the concepts documented on related wiki pages [[Social_Engineering|Social Engineering and (Spear) Phishing]], [[Hardware Wallet Security|Cryptocurrency Hardware Wallet: Threat Model]] and [[login spoofing]] might also deepen understanding of this topic.

The following image is legitimate. It is a screenshot of the ClamTK Virus Scanner.

'''Figure:''' ''ClamTK Virus Scanner'' <ref>
* https://www.whonix.org/wiki/File:ClamTk_4.30.png
* https://en.wikipedia.org/wiki/ClamTk
</ref>

[[File:ClamTk_4.30.png]]

These are real windows. The window decoration (minimize to tray, maximize, close buttons) as well as the window itself is drawn by the operating system. Responsible for the window title and content of the window is the application, ClamTK.

= Exceptions =

Some URLs in Firefox, Chrome and Tor Browser are special such as <code>about:config</code> or <code>about:preferences</code>. Content of these is not generated by websites but by the browser itself.

[https://forums.whonix.org/t/very-hard-to-notice-phishing-scam-firefox-tor-browser-url-not-showing-real-domain-name-homograph-attack-punycode/8373 very hard to notice Phishing Scam - Firefox / Tor Browser URL not showing real Domain Name - Homograph attack (Punycode)]

= Advanced Topics =

When rebooting it is in theory not guaranteed that one will see the real BIOS. It is possible that the user is only presented a fake reboot, i.e. the real operating system keeps running normally but shows a graphical simulation of a full reboot sequence. There is no confirmation that this technique has ever been deployed in practice.

= See Also =

* [[Social_Engineering|Social Engineering and (Spear) Phishing]]
* [[Hardware Wallet Security|Cryptocurrency Hardware Wallet: Threat Model]]
* [[login spoofing|Login Spoofing]]
* [[Malware]]
* [[Dev/Threat_Model|{{project_name}} Threat Model]]

= External =

<div style="column-count:2;-moz-column-count:2;-webkit-column-count:2">
* [https://www.geeksforgeeks.org/threat-modelling/ GeeksforGeeks: Threat Modelling]
* [https://csrc.nist.gov/CSRC/media/Publications/sp/800-154/draft/documents/sp800_154_draft.pdf Guide to Data-Centric System Threat Modeling]
* [https://www.linddun.org/ Linddun: privacy threat modeling methodology]
* [https://web.archive.org/web/20210711215728/https://github.com/devbret/online-opsec Online Operations Security (OpSec)]
* [https://cheatsheetseries.owasp.org/cheatsheets/Threat_Modeling_Cheat_Sheet.html OWASP Cheat Sheet Series: Threat Modeling Cheat Sheet]
* [https://versprite.com/tag/pasta-threat-modeling/ PASTA Threat Modeling]
* [https://www.privacyguides.org/threat-modeling/ Privacy Guides: What are threat models?]
* [https://insights.sei.cmu.edu/blog/threat-modeling-12-available-methods/ Software Engineering Institute: Threat Modeling: 12 Available Methods]
* [https://en.wikipedia.org/wiki/STRIDE_%28security%29 STRIDE threat modeling]
* [https://www.threatmodelingmanifesto.org/ Threat Modeling Manifesto]
* https://imgs.xkcd.com/comics/authorization.png
</div>

= Footnotes =
<references />

{{Footer}}

[[Category:Documentation]]
