<!--
Copyright:

   {{project_name}} Trust wiki page Copyright (C) Amnesia <amnesia at boum dot org>
   {{project_name}} Trust wiki page Copyright (C) 2012 - 2020 ENCRYPTED SUPPORT LP <adrelanos@riseup.net>
   
   This program is free software; you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation; either version 3 of the License, or
   (at your option) any later version.
         
   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.
      
   You should have received a copy of the GNU General Public License
   along with this program; if not, write to:

    Free Software Foundation, Inc. 
    51 Franklin St, Fifth Floor
    Boston, MA 02110-1301, USA.

On Debian GNU/Linux systems, the complete text of the GNU General Public
License can be found in the /usr/share/common-licenses' directory.

The complete text of the GNU General Public License can also be found online on gnu.org <https://www.gnu.org/licenses/gpl.html>, in {{project_name}} virtual machine images in /usr/share/common-licenses/GPL-3 file or on Github <https://github.com/{{project_name_short}}/{{project_name_short}}/blob/master/GPLv3>.
-->
<!--
The Introduction chapter of this website is forked from the Tails trust page, from this exact source <http://git.immerda.ch/?p=amnesia.git;a=blob;f=wiki/src/doc/about/trust.mdwn;hb=d249db72228b498407d85fb762b49ec155871ded>.
-->
{{Title|title=Placing Trust in {{project_name}}}}
{{Header}}
{{#seo:
|description=Is {{project_name}} trustworthy? Is there a backdoor in {{project_name}}? How does {{project_name}} protect itself from backdoors?
|image=https://www.whonix.org/w/images/4/4d/Candle-335965-640.jpg
}}
= Introduction =

Trust is a very problematic issue. This is the essence of why security is difficult in every field, including general computing and Internet communication. A skeptical user might ask themselves the following questions before relying upon {{project_name}} for sensitive activities on a daily basis:

* Can {{project_name}} and its developers be trusted?
* Are backdoors present in {{project_name}} that can take control over a computer or exfiltrate data?
* Does {{project_name}} generate compromised encryption keys to enable government spying?
* How trustworthy and sincere are the stated anonymity goals of the {{project_name}} project?

Opinions will vary widely, but the reasoning process used to reach the conclusion should be closely examined. It is important that both trust and distrust are based on facts, and not gut feelings, instincts, paranoid conceptions, unfounded hearsay or the words of others. 

It is unsurprising that the {{project_name}} project and other anonymity platforms / tools claim to be honest, but written assurances are worthless. For an informed decision, it is worth looking at the bigger {{project_name}} picture: core components, affiliations, project track record,  and how reasonable trust might be established.

{{Anchor|Free Software and Public Scrutiny}}
== Freedom Software and Public Scrutiny ==

{{project_name}} and other Freedom Software makes it possible to check the source code to determine how a software distribution functions and what it consists of. Suitably skilled individuals can thoroughly audit the code to search for the presence of any malicious code, like a backdoor. In addition, software can be manually built from source code and the result compared against any versions that are pre-built and already being distributed, like the {{project_name}} ova images that can be [[Download|downloaded]] from {{code|whonix.org}}. This comparison can determine whether any malicious changes were made, or if the distributed version was actually built with the source code.

Naturally most people do not have the requisite knowledge, skills or time to properly audit software. However, the public scrutiny of popular, open source software implies a certain degree of trustworthiness. The axiom attributed to Linus Torvalds <ref>Creator of the Linux kernel.</ref> -- "Given enough eyeballs, all bugs are shallow" -- is a reasonable assumption in user communities that are large, vibrant, and focused on fixing security vulnerabilities quickly. <ref>https://www.govtechworks.com/open-source-is-safe-but-not-risk-free/</ref> The Freedom Software community has a strong tradition of publicly reporting and resolving serious issues, and a large pool of developers and beta testers can help to identify and remedy problems. <ref>On the flip-side, there is no guarantee that just because software is open to review, that sane reviews will actually be performed. Further, people developing and reviewing software must know the principles of secure coding.</ref>

== Trusting Debian GNU/Linux ==

Nearly all the software shipped in {{project_name}} comes from the [http://www.debian.org/ Debian GNU/Linux distribution]. Debian's packages are heavily scrutinized as it is one of the [https://distrowatch.com/table.php?distribution=debian largest Linux distributions] at present. Debian is also one of the most popular distributions for derivative platforms; [https://distrowatch.com/table.php?distribution=ubuntu Ubuntu Linux] is a Debian derivative, and the same applies to all Ubuntu derivatives such as [https://distrowatch.com/table.php?distribution=mint Linux Mint]. 

The sheer number using Debian's software packages and the large developer pool inspecting software integrity are significant factors in Debian's favor. Debian regularly identifies and patches [https://www.debian.org/security/ serious security issues] like the infamous SSH PRNG vulnerability <ref>https://lists.debian.org/debian-security-announce/2008/msg00152.html ([http://www.webcitation.org/6EnxsukxM w])</ref>, but backdoors or other purposeful security holes have never been discovered to date. Debian's focus on security is further evidenced by their Security Audit team which constantly searches for new or unfixed security issues. <ref>Debian also participates in security standardization efforts and related overarching projects.</ref>

== Trusting Tor ==

{{project_name}} anonymity is based on Tor, which is developed by [https://www.torproject.org/ The Tor Project]. Tor is a [[Why_does_{{project_name_short}}_use_Tor|mature anonymity network with a substantial user base]], and it has developed a solid reputation after more than 15 years of development. Tor's distributed trust model makes it difficult for any single entity to capture a user's traffic and identify them on a consistent basis.

Tor and its general development are subject to heavy public scrutiny by academics, security professionals and a host of developers. <ref>And undoubtedly advanced adversaries.</ref> For example, there is a body of Tor research related to potential attack vectors on onion routing and the adequacy of current defenses, and the source code has undergone several external audits. Like any software project, numerous security issues have been identified and resolved over the years, but a purposeful backdoor has never been discovered. <ref>That said, a skilled, malicious coder is far more likely to introduce subtle errors that open non-obvious attack vectors.</ref> Theories about deliberate backdoors in Tor are considered highly speculative and lacking any credible basis.

== Trusting {{project_name}} ==

In one sense, {{project_name}} is the simple union of Debian and Tor and a mechanism to glue them together. If a user already  trusts Debian and The Tor Project, then a method for assessing {{project_name}} trustworthiness is also necessary. 

The {{project_name}} project was founded on 11 January, 2012. It previously existed under [[History|different project names]], including TorBOX and aos. As mentioned earlier, {{project_name}} is Freedom Software which makes the source code available for inspection. In the main, {{project_name}} is comprised of specifications for which Debian software packages should be installed and their appropriate configuration. See also [[Security Reviews and Feedback|this list of notable reviews and feedback about the security of {{project name}}]].

With a relatively small development team and estimated user base, the "many eyeballs" theory may work against {{project_name}} at present. However, the source code is comparably small and devoid of complexities, meaning the project is in relatively good shape compared to many other similar projects. Interested readers can learn more about the {{project_name}} specification and design [[Design|here]]. <ref>This is a good starting point to understand how {{project_name}} works.</ref>

With these factors in mind, the reader can now make an informed decision about the trustworthiness of {{project_name}}.

{{Anchor|canary}}

== {{project_name}} Warrant Canary ==

{{mbox
| type    = notice
| image   = [[File:Ambox_notice.png|40px|alt=Info]]
| text    = The first {{project_name}} warrant canary went live on 13 March, 2019. <ref>https://forums.whonix.org/t/whonix-warrant-canary/3208/18
</ref>
}}

The {{project_name}} [https://www.canarywatch.org/ warrant canary] is intended to provide a means of communication to users in the event {{project_name}} is served with a secret subpoena, despite legal prohibitions on revealing its existence. For any canary in force, once the signature of the canary file is verified with OpenPGP, this confirms that no warrants have been served on the {{project_name}} project. 

<u>Note:</u> the canary date of issue is represented by the gpg signature date. A new canary should be released within 4 weeks. <ref>Meaning doubts should surface if a new canary was not issued for longer than 4 weeks.</ref>

The canary and signature are available here:

* Canary text file: https://download.whonix.org/whonixdevelopermetafiles/canary/canary.txt ([http://download.dds6qkxpwdeubwucdiaord2xgbbeyds25rbsgr73tbfpqpt4a6vjwsyd.onion/whonixdevelopermetafiles/canary/canary.txt v3 onion])
* OpenPGP signature: https://download.whonix.org/whonixdevelopermetafiles/canary/canary.txt.asc ([http://download.dds6qkxpwdeubwucdiaord2xgbbeyds25rbsgr73tbfpqpt4a6vjwsyd.onion/whonixdevelopermetafiles/canary/canary.txt.asc v3 onion])

As a backup, the canary and signature are also available on github: <ref>If issues arise with the whonix.org server, this ensures the canary is always available online.</ref>

* https://github.com/{{project_name_short}}/canary
* https://github.com/adrelanos/canary

Readers are reminded this canary scheme is <u>not</u> infallible. The canary declaration is provided without any guarantee or warranty, and it is not legally binding upon any parties in any form. The signer should never be held legally responsible for any statements made in the canary.

= Trusting Downloaded Images =

Users should not blindly trust the {{project_name}} project or its developers. Logically it is unwise to trust unknown persons, especially on the Internet. On that basis, trust in {{project_name}} founder Patrick Schleizer should not rely on his public persona or the appearance of the {{project_name}} project alone. {{project_name}} may be or could become a high profile target, and it is risky to assume that Schleizer's build machine would remain clean under those circumstances.

Binary images can be trusted to some extent if a user verifies that they received exactly the same code as thousands of other users, and no one has found or publicly reported any serious security issues. This requires verification of the {{workstation_product_name}} and {{gateway_product_name}} images using the available OpenPGP signatures. <ref>This feature has been available since {{project_name}} 0.4.5</ref> All binary releases and source code tags for releases are OpenPGP-signed by lead {{project_name}} developer Patrick Schleizer. 

In order of increasing security, the {{project_name}} images can be:

# Downloaded via {{Code|https://whonix.org}}. TLS provides some trust and integrity of the hash file, but it is still advisable to check the site's certificate and perform manual OpenPGP verification. 
# Downloaded over the [http://{{project_onion}} {{project_name}} v3 onion address] with Tor Browser before OpenPGP verification. Onion addresses provide a higher standard of authentication than clearnet addresses.
# [[BuildDocumentation|Built from source]] since it is a relatively easy procedure. <ref>[[Trust#Verifiable_Builds|Verifiable Builds]] allow auditors to check if there is hidden code inside {{project_name}}.</ref>
= Trusting the {{project_name}} Website =
== Web Application Shortcomings ==

As noted in the [[Privacy Policy Technical Details#Privacy on the {{project_name}} Website|Privacy on the  {{project_name}} Website]] chapter, three separate web-based platforms are currently in use:

# [https://www.discourse.org/ Discourse] for the {{project_name}} forums.
# [https://www.mediawiki.org/wiki/MediaWiki MediaWiki] for online documentation.
# [https://phabricator.wikimedia.org/ Phabricator] (mostly) for the {{project_name}} project's issue/bug tracker.

The problem is these web applications (web apps) are developed independently from {{project_name}}. This means {{project_name}} developers have little to no control over the course these projects take. Since privacy and security issues often take a back seat to "enhanced features", websites relying on these or similar web apps can at best only provide <u>privacy by policy</u>, which is equivalent to a promise. 

It is infeasible from a monetary, time and manpower perspective to address perceived shortcomings in these web apps. This means the {{project_name}} community should not place undue trust in the live version of this site on the Internet, due to the potential for interference.

== Distrusting Infrastructure ==

In an identical fashion to the Qubes project, {{project_name}} has adopted the principle that all infrastructure should be explicitly distrusted. Infrastructure in this context refers to "...hosting providers, CDNs, DNS services, package repositories, email servers, PGP keyservers, etc."

Third parties who operate infrastructure are "known unknowns" and potentially hostile. It is safer to voluntarily place trust in a few select entities, such as the contributors of {{project_name}} packages, the holder(s) of {{project_name}} signing keys and so on. By sufficiently securing endpoints, it is unnecessary to try and improve the trustworthiness of those operating the "mid-points". This also provides two benefits: {{project_name}} forgoes the need to invest valuable resources on the problem, and no illusory security expectations are raised in the {{project_name}} community.

[https://www.qubes-os.org/faq/#what-does-it-mean-to-distrust-the-infrastructure Quote] [https://www.qubes-os.org/ Qubes OS] (security-focused operating system):

<blockquote>What does it mean to “distrust the infrastructure”?

A core tenet of the Qubes philosophy is “distrust the infrastructure,” where “the infrastructure” refers to things like hosting providers, CDNs, DNS services, package repositories, email servers, PGP keyservers, etc. As a project, we focus on securing endpoints instead of attempting to secure “the middle” (i.e., the infrastructure), since one of our primary goals is to free users from being forced to entrust their security to unknown third parties. Instead, our aim is for users to be required to trust as few entities as possible (ideally, only themselves and any known persons whom they voluntarily decide to trust).

Users can never fully control all the infrastructure they rely upon, and they can never fully trust all the entities who do control it. Therefore, we believe the best solution is not to attempt to make the infrastructure trustworthy, but instead to concentrate on solutions that obviate the need to do so. We believe that many attempts to make the infrastructure appear trustworthy actually provide only the illusion of security and are ultimately a disservice to real users. Since we don’t want to encourage or endorse this, we make our distrust of the infrastructure explicit.

[https://www.qubes-os.org/faq/#should-i-trust-this-website Also see: Should I trust this website?]</blockquote>

== Self-Hosting vs Third Party Hosting ==

Some users mistakenly believe that servers of security-focused projects are virtually impenetrable and hosted in the homes of developers; this is not the case. The whonix.org server is actually hosted at an Internet hosting company. Similarly, [https://www.torproject.org The Tor Project] and [https://tails.boum.org Tails] servers are not hosted in a developer's home either -- this arrangement is the exception, rather than the rule. At the time of writing, there are no known cases where servers are hosted in a developer's home. This means employees of the associated Internet hosting company have physical access rights to the server, along with any other capable, malicious actors.

Since virtually every project is hosted by a third party (an Internet hosting company), the capability to  physically secure server hardware is largely forfeited. Without physical security and due to the risk of untrusted visitors, a hardware backdoor could easily compromise the security of the server.

Any demand that servers ought to be super secure and hosted in a developer's home is idealistic. Home Internet connections are generally too slow to meet the requirements of a public web server in terms of traffic quota and connection upload speed. Internet service providers (ISPs) do not usually allow a busy public web server to be hosted on home connections; throttled connections or terminated contracts are likely if that happens. 

The "proper solution" would require purchase of a business Internet uplink, similar to becoming an Internet hosting company. This would incorporate a business building with a good Internet uplink, full camera security, security officers and so forth. Unfortunately this is economically infeasible at the current stage of project development.

== Security Level ==

Many [[Trust#Trusting_the_Whonix_.E2.84.A2_Website|web applications]] in use by whonix.org did not provide software signatures at the time of installation or still do not provide them. Therefore, in stark contrast to software installed by default in {{project name}}, for the whonix.org server it was not possible to always enforce [[Verifying Software Signatures|verification of software signatures]]. 

Many web application and extensions updaters did not, or still do not, securely verify software signatures. Therefore, the [[Verifying_Software_Signatures#System_Security_Level|security level]] of most servers is probably only equivalent to <code>plaintext</code>. In the case of the whonix.org server, the system security level is only equivalent to <code>always use TLS</code> and not <code>always use software signatures verification</code>.

== Server Privacy ==

In the past, various suggestions for "perfect server privacy" <ref>Using quotes since this is not well defined. </ref> were made such as [[#Self-Hosting vs Third Party Hosting|"self-hosting in developers' homes"]] or "host the server outside the [https://en.wikipedia.org/wiki/Five_Eyes five eyes] ([https://en.wikipedia.org/wiki/UKUSA_Agreement#9_Eyes,_14_Eyes,_and_other_%22third_parties%22 nine eyes, fourteen eyes]) countries". Despite the good intentions, these suggestions do not easily translate into an actionable plan.

First, these suggestions assume there is a sane method of rating the privacy protections afforded by a specific country. Moreover, the privacy rights granted for local citizens in a specific jurisdiction do not necessarily extend to non-citizens. {{project_name}} developers are unaware of any project that rates privacy protections in this way, considers the feasibility of operating servers (by running tests), and then makes recommendations for locations which provide the best possible privacy.

In [[The_World_Wide_Web_And_Your_Privacy|today's world]] following the Snowden disclosures, it has to be assumed that if surveillance is possible it is being done. The likelihood is that surveillance is undertaken in all jurisdictions, and it is only a matter of degree.

Even The Tor Project -- a much older,  established and better funded organization -- does not attempt to implement any suggestion concerning "perfect server privacy". As noted on their [https://www.torproject.org/about/sponsors/ sponsor's page]:

<blockquote>Fastly generously hosts our Tor Browser update downloads that can be fetched anonymously.</blockquote>

[https://www.fastly.com/ Fastly] is providing content delivery network (CDN) services and is headquartered in America (arguably the most aggressive member of the five eyes network). Even [https://forums.whonix.org/t/debian-apt-get-updates-over-https-ssl-tls-by-default-or-avoiding-amazon-aws-pick-one/6272 Debian uses CDNs Amazon AWS and Fastly].

In a similar fashion to the [[#Distrusting Infrastructure|Distrusting Infrastructure]] chapter, {{project name}} has concluded it is not worthwhile investing valuable resources to try and provide "perfect server privacy", because it is simply uneconomical. For this reason, the viewpoint that no undue trust should be placed in the server arrangements is made explicit.

== Server Security ==

Server security issues should not be conflated with software security issues. If an advanced adversary wanted to tarnish the reputation of any security-focused project, then breaking into the data center where it was hosted and "hacking" them would be one way to achieve that aim. Projects that are honest need to mention this possibility beforehand, so it is not unexpected.

The world's largest and most profitable technology companies like Google, Facebook, Microsoft and Amazon can easily afford to employ large, dedicated and skilled teams of system administrators to work around the clock to protect their servers. <ref>Even then, capable adversaries have hacked their servers in the recent past; see [https://www.theatlantic.com/politics/archive/2013/10/nsa-hacked-google-and-yahoos-private-networks/354570/ here].</ref> For small projects, this scale of server protection is completely unrealistic.

== Server Privacy vs Server Security ==
In an ideal world, both server privacy and server security would be maximized at the same time. However, in the real world it is impossible to maximize both server privacy and server security at the same time.

In a world with specialization and division of labour those companies specialized at hosting webapps have more focus, time, energy, knowledge and money to work on server security. It's their means in itself. Small projects use webapps only as a means to an end. Therefore using third party webapp hosters may provide better security than self-hosting. However, for better server privacy it is required to self-host. Therefore these are unfortunately contradictory goals which cannot be optimized at the same time.

== Server Downtime ==
The almost perfect uptime of popular web services such as google, facebook, and amazon (maybe around 99.99 %) might lead some to the conclusion that this is something which is easy to provide. This is a false assumption.

Expecting the same uptime from much smaller projects such as {{Project name}} is unrealistic. Maybe only 99.0 % uptime can be provided. No resources are spent on server uptime statistics. Server upgrades need to be performed. Reboots are necessary. These lead to downtime (website unavailable). With a huge budget it would be possible to have the 99.99 % uptime that popular websites have with technical solutions such as server farms, load balancing, and failover, but for small projects this is not feasible. Big companies can afford to pay for such technical solutions and whole teams of system administrators who are working 24/7. Small projects do not have that.

Server downtime is not evidence of server compromise but server issues (such as perhaps failing hard drives) and server maintenance.

== Conclusion ==
Due to these issues, the software produced by the {{Project name}} project is in theory to be always considered more secure than the website of the {{Project name}} project {{Project name short}}.org. The software {{Project name}} is the main product by the {{Project name}} project. The server {{Project name short}}.org is only a tool to document and deliver {{Project name}}.

= OpenPGP =
== Introduction ==
{{always verify signatures reminder}}

== Fingerprint Trust ==

Most users retrieve OpenPGP fingerprints directly from a website and then download an associated key from a key server. The problem with this method is that TLS is fallible and the connection could be insecure or broken. Greater security necessitates a key signing party, whereby a direct and trusted path of communication can be confirmed by all attendees. If this step is not followed, OpenPGP is only secure as TLS. 

It is often impossible to meet this condition of meeting in person. To mitigate the risk, any OpenPGP fingerprint should be cross-referenced on multiple "secure" (<code>https://</code>) sites. An additional fail-safe is to use an alternative authentication system, for example comparing the Tor signing keys on both the clearnet and onion domains: https://www.torproject.org/docs/signing-keys.html and http://expyuzz4wqqyqhjn.onion/docs/signing-keys.html

Onion services offer strong authentication via [https://www.torproject.org/docs/onion-services multiple layers of encryption]. This does not prohibit an advanced adversary from trying to impersonate an onion service, but together with multiple fingerprint sources, it becomes increasingly difficult and improbable that a single entity could impersonate them all.

== {{project_name}} Binaries and Git Tags ==

All {{project_name}} binaries are OpenPGP-signed by {{project_name}} developer Patrick Schleizer. <ref>{{project_name}} developer ([http://www.webcitation.org/6Eny0UfAI w]), [https://trac.torproject.org/projects/tor/wiki/doc/proper?version=1 named proper in the past] ([http://www.webcitation.org/6Fg1zUNeQ w]), [https://trac.torproject.org/projects/tor/wiki/doc/proper?version=6 renamed himself to adrelanos] ([http://www.webcitation.org/6Fg2p2YK3 w]), [https://trac.torproject.org/projects/tor/wiki/doc/proper?version=3 published his OpenPGP key on 05/29/12] ([http://www.webcitation.org/6Fg336X1H w]) ([https://trac.torproject.org/projects/tor/wiki/doc/proper?action=history wiki history] ([http://www.webcitation.org/6Fg24cX1W w])). [https://www.whonix.org/blog/giving-up-pseudonymity-after-collecting-experiences-with-pseudonymous-project-development/ Revealed his identity on 01/18/14.] [http://www.webcitation.org/6Nl4kSDM8 (w)] [https://lists.torproject.org/pipermail/tor-talk/2014-January/031741.html Patrick Schleizer posted his OpenPGP key transition message on 01/18/14, signed by both his old and new key.] [http://www.webcitation.org/6Nl4neAFt (w)]</ref> The source code is directly available on github over TLS, and it can be cloned using git over <code>https://</code>. Git tags for each release are also OpenPGP-signed by {{project_name}} developer Patrick Schleizer. Users can also request signed git development tags from the same developer.

Even if {{project_name}} developers are distrusted, verifying binary downloads or git tags with OpenPGP is still useful. For example in order to audit {{project_name}}, it is important to verify the download came from {{project_name}} developers and that it was not tampered with by third parties. This is a realistic threat, as these recent examples show:

* [http://www.extremetech.com/computing/120981-github-hacked-millions-of-projects-at-risk-of-being-modified-or-deleted An attacker could modify source codes on github] ([http://www.webcitation.org/6Eny2zbS1 w])
* [http://sourceforge.net/blog/sourceforge-attack-full-report/ sourceforge hacked] ([http://www.webcitation.org/6Eny40bV9 w])
* [http://www.theregister.co.uk/2012/09/26/sourceforge_backdoor_code_compromise/ sourceforge mirror hacked] ([http://www.webcitation.org/6Enz6vyNP w])

The OpenPGP key also ensures that if the {{project_name}} infrastructure is ever compromised by a powerful adversary (such as a domain takeover), the original {{project_name}} developers can at least prove they owned the infrastructure.

== {{project_name}} Developer OpenPGP Guidelines ==

All long-term {{project_name}} developers are encouraged to:

* Create a 4096/4096 RSA/RSA OpenPGP key.
* Retrieve the latest {{code|gpg.conf}} which comes with {{workstation_product_name}} for stronger hashes, no-emit-version, and other improved settings.
* Store the private key inside an encrypted file.
* Make a backup of that encrypted file.
* Remember the password and regularly test one's memory of it.
* Upload the encrypted file to a (free) online cloud-based host to protect against theft, fire, natural events and so on.

From the beginning of the {{project_name}} project, greater trust has been placed in developers who publish their OpenPGP public key earlier on, since this reduces the probability of an [[#Evil_Developer_Attack|evil developer attack]].

= Verifiable Builds =

== Verifiable .ova Releases ==

{{Verifiable Ovas Introduction}}

This is only an an introduction to this topic; see [[Verifiable Builds]] for full details.

== Verifiable {{project_name}} Debian Packages ==

{{Verifiable Pkgs Introduction}} For full details on this topic, see [[Verifiable Builds#Verifiable {{project_name}} Debian Packages|Verifiable {{project_name}} Debian Packages]].

= {{project_name}} Updates =

== Introduction ==

An optional updater has been available in {{project_name}} since version 6 of the platform. <ref>When {{project name}} APT repository is disabled, there is no updater - as was the case in {{project_name}} 0.5.6 and below.</ref> When it comes to trust, there is a large difference between building {{project_name}} from source code and using the Default-Download-Version.

== APT Repository and Binary Builds Trust == 

When {{project_name}} is built with the build script and the source code is verified to be non-malicious and reasonably bug-free, {{project_name}} developers are unable to access the system. On the other hand, if {{project name}} APT repository is enabled, developers holding a {{project_name}} repository signing key could release a malicious update to gain full access to the machine(s). <ref>At the moment, {{project_name}} developer Patrick Schleizer is the only one holding the {{project_name}} APT repository OpenPGP signing key.</ref>

Even if the {{project_name}} APT repository is not used with the Default-Download version, it is still theoretically possible for {{project_name}} developers to sneak a backdoor into the binary builds which are available for download. <ref>See the [[Verifiable Builds]] section for further details.</ref> Although an unpleasant threat, using {{project name}} APT repository poses a greater risk: a malicious {{project_name}} developer might sneak in a backdoor at any time. 

It is easier to sneak backdoors into binary builds, since they contain compiled code in binary packages which are downloaded from the Debian repository when built. The actual {{project_name}} deb packages do not yet have any compiled code, and consist of only configuration files, scripts, and comments. <ref>Although these could change with a malicious update.</ref> The lack of compiled code inside {{project_name}} deb packages at present might make it easier for auditors searching for a backdoor in updated deb packages, <ref>Unless it is a targeted attack.</ref> compared to the binary builds.

== APT Repository Default Settings ==

<u>[[{{non q project name short}}|{{non q project name}}]]:</u>

* [[Dev/Build Documentation|Building]] from source code: {{project name}} APT Repository is ''disabled by default.'' <ref>Since {{project_name}} version 7.3.3</ref>
* Default [[Download|binary download]]: {{project name}} APT Repository is ''enabled by default.'' 

<u>[[{{q_project_name_short}}|{{q_project_name}}]]:</u>

* [[Qubes/Install]]: {{project name}} APT Repository is ''enabled by default.''
* [[Dev/Build Documentation|Building]] from source code: {{project name}} APT Repository is ''enabled by default.'' <ref>To disable this setting, see: [https://github.com/{{project_name_short}}/qubes-template-whonix qubes-template-whonix]: [https://github.com/{{project_name_short}}/qubes-template-whonix/blob/master/builder.conf <code>builder.conf</code>], and set <code>WHONIX_APT_REPOSITORY_OPTS = off</code></ref>

Most users will have the {{project_name}} APT repository enabled. This means when updated {{project_name}} debian packages are uploaded to the {{project_name}} APT repository, these packages will be automatically installed when the system is upgraded. <ref>After running <code>sudo apt-get update && sudo apt-get dist-upgrade</code> manually or via a GUI updater.</ref> If this behavior is unwanted, this can be [[{{project name short}}-APT-Repository#Disable_{{project_name_short}}_APT_Repository|disabled]]. Refer to the previous section outlining security implications before proceeding.

== Security Conclusion ==

Legend:

* *: poor security.
* ****: best security.

'''Table:''' ''Build and APT Repository Security Comparison''

{| class="wikitable" style="background-color: #fff;text-align: center"
! 
! Binary Download with {{project_name}} APT Repository
! Binary Download without {{project_name}} APT Repository
! Built from Source Code and {{project_name}} APT Repository Enabled
! Built from Source Code and {{project_name}} APT Repository Disabled
|-
! Security
| style="background-color: {{Red}}"| *
| style="background-color: {{Yellow}}"| **
| style="background-color: {{Red}}"| ''*''
| style="background-color: {{Green}}"| ****
|-
! Convenience
| style="background-color: {{Green}}"| ****
| style="background-color: {{Red}}"| ''*''
| style="background-color: {{Yellow}}"| **
| style="background-color: {{Red}}"| *
|}

In summary:

* The {{project_name}} binary download using the {{project_name}} APT repository is the most convenient method, but also the least secure. 
* It is somewhat safer to use the {{project_name}} binary download and then disable the {{project_name}} APT repository. However, the user must then manually download updated {{project_name}} deb packages upon release, and independently verify and install them.
* The greatest security comes from [[Dev/Build_Documentation|building {{project_name}}]] and updated packages from source code, particularly if the source code is verified before building {{project_name}}.

= Appendix =

== What Digital Signatures Prove ==

See [[Verifying_Software_Signatures|Verifying Software Signatures]] for details on what digital signatures prove. In short, a user must be careful to ensure the public keys that are used for signature verification are the [[{{project name short}} Signing Key|bona fide {{project_name}} key pair]] belonging to Patrick Schleizer.

== TLS ==

TLS, SSL and HTTPS are all flawed since they rely on the vulnerable Certificate Authority (CA) model; see [[Warning#The_Fallible_Certificate_Authority_Model|here]] for further details and SSL/TLS alternatives. <ref>{{project_name}} developers place little trust in the CA model. Even if the numerous implementation problems were solved, such as problematic revocation and the ability for every CA to issue certificates for anything (including "*"), third party trust cannot be established. Until an alternative arrives and is widely adopted, everybody has to rely upon SSL/TLS to some extent.</ref>

== Evil Developer Attack ==

=== Introduction ===

An "evil developer attack" is a narrow example of an ''insider threat'': <ref>https://www.se.rit.edu/~samvse/publications/An_Insider_Threat_Activity_in_a_Software_Security_Course.pdf</ref>

<blockquote>Software development teams face a critical threat to the security of their systems: insiders.<br />

[...]

An insider threat is a current or former employee, business partner, or contractor who has access to an organization’s data, network, source code, or other sensitive information who may intentionally misuse this information and negatively affect the availability, integrity, or confidentiality of the organization’s information system.</blockquote>

In the case of software, a disguised attack is conducted on the integrity of the software platform. While this threat is only theoretical, it would be naive to assume that no major software project has ever had a malicious insider. {{project_name}} and all other open source software projects face this problem, particularly those that are focused on anonymity such as VeraCrypt, <ref>TrueCrypt has been discontinued.</ref> Tails, I2P, The Tor Project and so on.

=== Attack Methodology ===

A blueprint for a successful insider attack is as follows:

# Either start a new software project or join an existing software project.
# Gain trust by working hard, behaving well, and publishing your sources. 
# Build binaries directly from your sources and offer them for download. 
# Attract a lot of users by making a great product. 
# Continue to develop the product. 
# Make a second branch of your sources and add malware. 
# Continue to publish your clean sources, but offer your malicious binaries for download. 
# If undetected, a lot of users are now infected with malware.

An evil developer attack is very difficult for end users to notice. If the backdoor is rarely used, then it may remain a secret for a long time. If it was used for something obvious, such as adding all the users to a botnet, then it would be quickly discovered and reported on. 

Open source software has some advantages over proprietary code, but certainly not for this threat model. For instance, no one is checking if the binaries are made from the proclaimed source and publishing the results, a procedure called "deterministic builds".<ref>https://mailman.stanford.edu/pipermail/liberationtech/2013-June/009257.html</ref> <ref>https://trac.torproject.org/projects/tor/ticket/3688</ref> This standard is quite difficult to achieve, but is being worked towards. <ref>Interested readers can investigate its complexity by searching with the phrase "trusting trust".</ref>

=== Related Attacks ===

While most security experts are focused on the possibility of a software backdoor, other insider attacks can have equally deleterious effects. For instance, the same methodology can be used to infiltrate a targeted project team but in a role unrelated to software development; for example, as a moderator, site administrator, wiki approver and so on. This approach is particularly effective in smaller projects that are starved of human resources.

Following infiltration, disruption is caused within the project to affect productivity, demoralize other team members and (hopefully) cause primary contributors to cease their involvement. For example, using a similar blueprint to that of the evil developer attack, a feasible scenario is outlined below:

# Join an existing software project as a general member.
# Gain trust by working hard, behaving well, assisting readily in forums, making significant wiki contributions and so on. 
# Attract a lot of community admiration by outwardly appearing to be a bona fide and devoted project member. 
# Eventually attain moderator, administrator or other access once team membership is extended. <ref>The time period is likely to be shorter for smaller projects, perhaps less than 12 months.</ref>
# Continue to behave, moderate and publish well.
# Once trust is firmly established, subtly undermine the authority, character and contributions of other team members. <ref>For example, by casting unjustified aspersions.</ref>
# If the insider threat is undetected for a significant period, this can lead to a diminished software product due to a fall in contributions in numerous domains and team ill will.

=== Conclusion ===

The insider threat nicely captures how difficult it is to trust developers or other project members, even if they are not anonymous. Further, even if they are known and have earned significant trust as a legitimate developer, this does not discount the possibility of serious mistakes that may jeopardize the user. The motives and internal security of everyone contributing to major software projects like Tor, distribution developers and contributors, and the hundreds of upstream developers and contributors is a legitimate concern. <ref>In the case of {{project_name}}, binaries are not distributed nor created. Only unmodified upstream binaries are distributed, along with shell scripts. This claim is much easier to verify than if {{project_name}} were distributing binaries from project source code.</ref>

The trusted computing base of a modern operating system is enormous. There are so many people involved in software and complex hardware development, that it would be unsurprising if none of the bugs in existence were intentional. While detecting software changes in aggregate may be easy (by diffing the hash sums), finding and proving that a change is a purposeful backdoor rather than a bug in well designed source code is near impossible.

== Other Projects Discussing Trust ==

* Tails is a live CD or USB that aims to preserve privacy and anonymity - [https://tails.boum.org/doc/about/trust/index.en.html Tails about trust.] ([http://www.webcitation.org/6EnyJvTnn w])
* I2P (anonymizing network) has also discussed [http://www.I2P2.de/how_threatmodel.html#dev development attacks]. ([http://www.webcitation.org/6EnyKSGdn w])
* [https://wiki.qubes-os.org/wiki/VerifyingSignatures Qubes OS: What do the Digital Signatures Prove and What They DO NOT Prove] ([http://www.webcitation.org/6EnyL8AQn w])
* [http://hyper.to/blog/link/attack-scenarios-software-distribution/ Miron’s Weblog: Attack Scenarios on Software Distributions] ([http://www.webcitation.org/6EnzaBTdP w])
* A list of incidents concerning compromised servers: [http://www.koch.ro/blog/index.php?/archives/153-On-distributing-binaries.html On distributing binaries] ([http://www.webcitation.org/6L1roljIe w])

= Footnotes / References =
{{reflist|close=1}}

= License =
{{License_Amnesia|{{FULLPAGENAME}}}}

{{Footer}}

[[Category:Documentation]]
